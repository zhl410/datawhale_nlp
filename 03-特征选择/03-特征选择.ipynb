{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词频-逆文档频率 TF-IDF## \n",
    "\n",
    "其实 IDF 的概念就是[一个特定条件下、关键词的概率分布的交叉熵（Kullback-Leibler Divergence）](https://www.cnblogs.com/ZisZ/p/9087921.html)\n",
    "\n",
    "[TF-IDF实现](https://www.geeksforgeeks.org/tf-idf-model-for-page-ranking/)\n",
    "\n",
    "[TF-IDF与余弦相似性的应用（一）](http://www.ruanyifeng.com/blog/2013/03/tf-idf.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词频TF ###\n",
    "\n",
    "$$tf = \\frac{某个词在文档中出现的次数}{文档的总词数}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逆文档频率IDF ###\n",
    "\n",
    "$$ idf = \\log\\frac{文档总数}{包含该词的文档数}$$\n",
    "通常还需要平滑处理，为什么是log?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF ###\n",
    "\n",
    " $$tf-idf = tf \\times idf$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ \"I come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t0.4424621378947393\n",
      "  (0, 15)\t0.697684463383976\n",
      "  (0, 4)\t0.4424621378947393\n",
      "  (0, 3)\t0.348842231691988\n",
      "  (1, 14)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 5)\t0.3574550433419527\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (2, 12)\t0.5\n",
      "  (2, 7)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (3, 18)\t0.3565798233381452\n",
      "  (3, 17)\t0.3565798233381452\n",
      "  (3, 15)\t0.2811316284405006\n",
      "  (3, 13)\t0.3565798233381452\n",
      "  (3, 11)\t0.3565798233381452\n",
      "  (3, 10)\t0.3565798233381452\n",
      "  (3, 8)\t0.3565798233381452\n",
      "  (3, 6)\t0.2811316284405006\n",
      "  (3, 5)\t0.2811316284405006\n"
     ]
    }
   ],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t0.4424621378947393\n",
      "  (0, 15)\t0.697684463383976\n",
      "  (0, 3)\t0.348842231691988\n",
      "  (0, 16)\t0.4424621378947393\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 14)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 5)\t0.3574550433419527\n",
      "  (2, 7)\t0.5\n",
      "  (2, 12)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (3, 15)\t0.2811316284405006\n",
      "  (3, 6)\t0.2811316284405006\n",
      "  (3, 5)\t0.2811316284405006\n",
      "  (3, 13)\t0.3565798233381452\n",
      "  (3, 17)\t0.3565798233381452\n",
      "  (3, 18)\t0.3565798233381452\n",
      "  (3, 11)\t0.3565798233381452\n",
      "  (3, 8)\t0.3565798233381452\n",
      "  (3, 10)\t0.3565798233381452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf2 = TfidfVectorizer()\n",
    "res = tfidf2.fit_transform(corpus)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 互信息-MI ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑两组变量$x$,$y$的联合概率分布$p(x,y)$, 如果两组变量是独⽴的，那么他\n",
    "们的联合分布可以分解为边缘分布的乘积$p(x, y) = p(x)p(y)$,如果变量不是独⽴的，那么我们可以通过考察联合概率分布与边缘概率分布乘积之间的Kullback-Leibler散度来判断它们是否“接近”于相互独⽴。这被称为变量x和变量y之间的互信息（mutual information）。根据Kullback-Leibler散度的性质，我们看到$I[x, y] \\ge 0$，当且仅当$x和$y相互独⽴时等号成⽴。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ I[x, y] = KL(p(x,y)||p(x)p(y))=-\\int\\int p(x,y)\\ln(\\frac{p(x)p(y)}{p(x,y)}dxdy)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使⽤概率的加和规则和乘积规则，我们看到互信息和条件熵之间的关系为:\n",
    "\n",
    "$$I[x, y] = H[x] − H[x | y] = H[y] − H[y | x]$$\n",
    "\n",
    "因此我们可以把互信息看成由于知道y值⽽造成的x的不确定性的减⼩（反之亦然）。从贝叶斯\n",
    "的观点来看，我们可以把p(x)看成$x$的先验概率分布，把$p(x | y)$看成我们观察到新数据$y$之后\n",
    "的后验概率分布。因此互信息表⽰⼀个新的观测$y$造成的$x$的不确定性的减⼩。\n",
    "\n",
    "![Mutual_Information](Mutual_Information.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mutual Information is a measure of the similarity between two labels of the same data. \n",
    "\n",
    "$$ MI(U,V)=\\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|} \\frac{|U_i\\cap V_j|}{N}\n",
    "        \\log\\frac{N|U_i \\cap V_j|}{|U_i||V_j|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mutual_info_score([2, 4], [7,9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env01(py36)",
   "language": "python",
   "name": "env01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
